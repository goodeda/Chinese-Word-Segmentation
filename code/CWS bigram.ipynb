{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b4db83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T22:14:44.060799Z",
     "start_time": "2021-12-23T22:14:44.055784Z"
    }
   },
   "source": [
    "## Chinese Word Segmentation (II)--statistical method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef01a2f",
   "metadata": {},
   "source": [
    "### Unigram is good but it did't consider the context. The probability of a word can rely on previous words.\n",
    "### Thus, bigram seems better since it takes the previous word into account. Given the a previous word, what is the likelihood of current word. \n",
    "## $P(W_{i}|W_{i-1})=\\frac{C(W_{i},W_{i-1})}{C(W_{i-1})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029f655e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T21:52:18.047064Z",
     "start_time": "2021-12-23T21:52:17.967208Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r'./training_and_testing_data/pku_training.txt',encoding='gbk') as f:# the path may need change\n",
    "    content=f.readlines()\n",
    "content=\"\".join(content).strip()\n",
    "#content=re.sub(\"。|？|！|\\n\",\"<end>\",content)\n",
    "content=content.split(\"\\n\")\n",
    "while '  ' in content:\n",
    "    content.remove('  ')\n",
    "while '' in content:\n",
    "    content.remove('')\n",
    "for i,sentence in enumerate(content):\n",
    "    content[i]=content[i].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1e23e",
   "metadata": {},
   "source": [
    "### Meanwhile, we should also consider a situation when the context becomes new. \n",
    "## That is the $P(W_{i}|W_{i-1})$ is very likely to be zero if there is a new context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91e130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T19:34:39.310108Z",
     "start_time": "2021-12-15T19:34:39.299229Z"
    }
   },
   "source": [
    "## We need interpolation!\n",
    "## $P^{'}(W_{i}|W_{i-1})=\\frac{C(W_{i-1})}{N_{1+}(W_{i-1})+C(W_{i-1})}*P(W_{i}|W_{i-1})+\\frac{N_{1+}(W_{i-1})}{N_{1+}(W_{i-1})+C(W_{i-1})}*P(W_{i})$\n",
    "## That measures what is likely to follow the previous word. Such as Hong Kong, perhaps the only word following \"Hong\" is \"Kong\", so the word type($N_{1+}(Hong)$) is very small, the probability will rely mostly on the conditional prob. On the other hand, for word \"New\", almost every noun can be the next word. So the $N_{1+}(Hong)$ will be pretty high, making the final prob tip a balance between its context and itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c516f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T21:52:21.544405Z",
     "start_time": "2021-12-23T21:52:20.750168Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "def biword_count(train_text):\n",
    "    count={\"<begin>\":0}#\n",
    "    for sentence in train_text:\n",
    "        count[\"<begin>\"]+=1\n",
    "        #count[\"<end>\"]+=1\n",
    "        for word in sentence.split(\"  \"):\n",
    "            if word in count:\n",
    "                count[word]+=1\n",
    "            else:\n",
    "                count[word]=count.get(word,0)+1\n",
    "    return count\n",
    "word_dict=biword_count(content)\n",
    "\n",
    "def pre_word_count(train_text):\n",
    "    pre_word_count={\"<begin>\":{}}#given a former word, what is the latter word\n",
    "    for sentence in train_text:\n",
    "        words_list=sentence.split(\"  \")\n",
    "        for i,word in enumerate(words_list):\n",
    "            if word not in pre_word_count:\n",
    "                pre_word_count[word]={}\n",
    "            if i ==0:\n",
    "                if word in pre_word_count[\"<begin>\"]:\n",
    "                    pre_word_count[\"<begin>\"][word]+=1\n",
    "                else:\n",
    "                    pre_word_count[\"<begin>\"][word]=pre_word_count[\"<begin>\"].get(word,0)+1\n",
    "            else:\n",
    "                if word in pre_word_count[words_list[i-1]]:\n",
    "                    pre_word_count[words_list[i-1]][word]+=1\n",
    "                else:\n",
    "                    pre_word_count[words_list[i-1]][word]=pre_word_count[words_list[i-1]].get(word,0)+1\n",
    "    return pre_word_count\n",
    "pre_word_dict=pre_word_count(content)\n",
    "def check_bigram_prob(pre,cur,pre_word_dict,word_dict):\n",
    "    if pre in pre_word_dict and cur in pre_word_dict[pre]:\n",
    "        return pre_word_dict[pre][cur]/word_dict[pre]\n",
    "    else:\n",
    "        return 0\n",
    "def check_unigram_prob(word,word_dict):\n",
    "    if word in word_dict:\n",
    "        return (1+word_dict[word])/(1109947+len(word_dict))\n",
    "    else:\n",
    "        return 1/(1109947+len(word_dict))\n",
    "def check_pre_count(pre_word,word_dict):\n",
    "    if pre_word in word_dict:\n",
    "        return word_dict[pre_word]+1\n",
    "    else:\n",
    "        return 1\n",
    "def check_pre_type(pre_word,pre_word_dict):\n",
    "    if pre_word in pre_word_dict:\n",
    "        return len(pre_word_dict[pre_word].keys())+1\n",
    "    else:\n",
    "        return 1\n",
    "def interpolated_prob(preword,word,pre_word_dict,word_dict):\n",
    "    if preword not in word_dict:\n",
    "        return -math.log(check_unigram_prob(word,word_dict))\n",
    "    elif word in pre_word_dict[preword]:\n",
    "        return -math.log(word_dict[preword]*check_bigram_prob(preword,word,pre_word_dict,word_dict)/(word_dict[preword]+check_pre_type(preword,pre_word_dict)*check_unigram_prob(word,word_dict)/(word_dict[preword]+check_pre_type(preword,pre_word_dict))))\n",
    "    else:\n",
    "        return -math.log(check_pre_type(preword,pre_word_dict)*check_unigram_prob(word,word_dict)/(word_dict[preword]+check_pre_type(preword,pre_word_dict)))\n",
    "#interpolated_prob(\"长江\",\"大桥\",pre_word_dict,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c09062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T21:52:24.275244Z",
     "start_time": "2021-12-23T21:52:24.190838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.49.3 (20211023.0002)\r\n -->\r\n<!-- Pages: 1 -->\r\n<svg width=\"417pt\" height=\"576pt\"\r\n viewBox=\"0.00 0.00 417.43 576.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.66 0.66) rotate(0) translate(4 873.59)\">\r\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-873.59 632,-873.59 632,4 -4,4\"/>\r\n<!-- End -->\r\n<g id=\"node1\" class=\"node\">\r\n<title>End</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"88\" cy=\"-29.35\" rx=\"25.22\" ry=\"25.22\"/>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"88\" cy=\"-29.35\" rx=\"29.2\" ry=\"29.2\"/>\r\n<text text-anchor=\"middle\" x=\"88\" y=\"-25.65\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">End</text>\r\n</g>\r\n<!-- Start -->\r\n<g id=\"node2\" class=\"node\">\r\n<title>Start</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"145\" cy=\"-837.64\" rx=\"27.9\" ry=\"27.9\"/>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"145\" cy=\"-837.64\" rx=\"31.9\" ry=\"31.9\"/>\r\n<text text-anchor=\"middle\" x=\"145\" y=\"-833.94\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Start</text>\r\n</g>\r\n<!-- 1 -->\r\n<g id=\"node3\" class=\"node\">\r\n<title>1</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"66\" cy=\"-736.7\" rx=\"18\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"66\" y=\"-733\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n</g>\r\n<!-- Start&#45;&gt;1 -->\r\n<g id=\"edge1\" class=\"edge\">\r\n<title>Start&#45;&gt;1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M114.72,-826.95C96.5,-819.38 74.82,-806.87 64,-787.7 60.08,-780.75 59.23,-772.36 59.75,-764.45\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"63.23,-764.87 61.08,-754.49 56.29,-763.94 63.23,-764.87\"/>\r\n<text text-anchor=\"middle\" x=\"97.5\" y=\"-776.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(赫|begin)</text>\r\n</g>\r\n<!-- 4 -->\r\n<g id=\"node6\" class=\"node\">\r\n<title>4</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"81\" cy=\"-475.7\" rx=\"18\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"81\" y=\"-472\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n</g>\r\n<!-- Start&#45;&gt;4 -->\r\n<g id=\"edge5\" class=\"edge\">\r\n<title>Start&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M145,-805.45C145,-785.97 145,-760.37 145,-737.7 145,-737.7 145,-737.7 145,-561.7 145,-538.62 144.34,-530.52 131,-511.7 124.57,-502.62 115,-495.1 105.95,-489.39\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"107.61,-486.3 97.21,-484.29 104.08,-492.35 107.61,-486.3\"/>\r\n<text text-anchor=\"middle\" x=\"231\" y=\"-646\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(赫尔辛基(Helsinki)|begin)</text>\r\n</g>\r\n<!-- 6 -->\r\n<g id=\"node8\" class=\"node\">\r\n<title>6</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"88\" cy=\"-301.7\" rx=\"18\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"88\" y=\"-298\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6</text>\r\n</g>\r\n<!-- Start&#45;&gt;6 -->\r\n<g id=\"edge9\" class=\"edge\">\r\n<title>Start&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M177.13,-835.06C233.67,-830.35 345,-811.69 345,-737.7 345,-737.7 345,-737.7 345,-387.7 345,-339.95 183.1,-314.45 116.3,-305.96\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"116.42,-302.45 106.07,-304.7 115.57,-309.4 116.42,-302.45\"/>\r\n<text text-anchor=\"middle\" x=\"486.5\" y=\"-559\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(赫尔辛基大学(University of Helsinki)|begin)</text>\r\n</g>\r\n<!-- 2 -->\r\n<g id=\"node4\" class=\"node\">\r\n<title>2</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"70\" cy=\"-649.7\" rx=\"18\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"70\" y=\"-646\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n</g>\r\n<!-- 1&#45;&gt;2 -->\r\n<g id=\"edge2\" class=\"edge\">\r\n<title>1&#45;&gt;2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M66.81,-718.49C67.36,-706.86 68.09,-691.24 68.72,-677.93\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"72.22,-678.02 69.19,-667.87 65.23,-677.7 72.22,-678.02\"/>\r\n<text text-anchor=\"middle\" x=\"96.5\" y=\"-689.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(尔|赫)</text>\r\n</g>\r\n<!-- 3 -->\r\n<g id=\"node5\" class=\"node\">\r\n<title>3</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"74\" cy=\"-562.7\" rx=\"18\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"74\" y=\"-559\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n</g>\r\n<!-- 2&#45;&gt;3 -->\r\n<g id=\"edge3\" class=\"edge\">\r\n<title>2&#45;&gt;3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M70.81,-631.49C71.36,-619.86 72.09,-604.24 72.72,-590.93\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"76.22,-591.02 73.19,-580.87 69.23,-590.7 76.22,-591.02\"/>\r\n<text text-anchor=\"middle\" x=\"100.5\" y=\"-602.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(辛|尔)</text>\r\n</g>\r\n<!-- 3&#45;&gt;4 -->\r\n<g id=\"edge4\" class=\"edge\">\r\n<title>3&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M74.25,-544.54C74.51,-534.88 75.01,-522.6 76,-511.7 76.23,-509.13 76.53,-506.46 76.85,-503.8\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"80.34,-504.12 78.21,-493.74 73.4,-503.19 80.34,-504.12\"/>\r\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-515.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(基|辛)</text>\r\n</g>\r\n<!-- 5 -->\r\n<g id=\"node7\" class=\"node\">\r\n<title>5</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"18\" cy=\"-388.7\" rx=\"18\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"18\" y=\"-385\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5</text>\r\n</g>\r\n<!-- 4&#45;&gt;5 -->\r\n<g id=\"edge6\" class=\"edge\">\r\n<title>4&#45;&gt;5</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M63.68,-470.14C48.95,-465.26 28.7,-455.93 19,-439.7 14.91,-432.85 13.63,-424.49 13.66,-416.58\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"17.15,-416.81 14.34,-406.6 10.17,-416.34 17.15,-416.81\"/>\r\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-428.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(大|基)</text>\r\n</g>\r\n<!-- 4&#45;&gt;6 -->\r\n<g id=\"edge8\" class=\"edge\">\r\n<title>4&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M81.7,-457.57C82.91,-427.7 85.43,-365.81 86.89,-329.97\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"90.4,-329.88 87.31,-319.75 83.4,-329.6 90.4,-329.88\"/>\r\n<text text-anchor=\"middle\" x=\"200.5\" y=\"-385\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(大学(University)|基 or 赫尔辛基 )</text>\r\n</g>\r\n<!-- 5&#45;&gt;6 -->\r\n<g id=\"edge7\" class=\"edge\">\r\n<title>5&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M14.19,-370.7C12.83,-360.39 12.91,-347.4 19,-337.7 28.17,-323.09 45.49,-314.33 60.49,-309.23\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"61.8,-312.49 70.37,-306.25 59.78,-305.79 61.8,-312.49\"/>\r\n<text text-anchor=\"middle\" x=\"46.5\" y=\"-341.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(学|大)</text>\r\n</g>\r\n<!-- 7 -->\r\n<g id=\"node9\" class=\"node\">\r\n<title>7</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"88\" cy=\"-214.7\" rx=\"18\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"88\" y=\"-211\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">7</text>\r\n</g>\r\n<!-- 6&#45;&gt;7 -->\r\n<g id=\"edge10\" class=\"edge\">\r\n<title>6&#45;&gt;7</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M88,-283.49C88,-271.86 88,-256.24 88,-242.93\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"91.5,-242.87 88,-232.87 84.5,-242.87 91.5,-242.87\"/>\r\n<text text-anchor=\"middle\" x=\"204\" y=\"-254.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(在|学 or 大学 or 赫尔辛基大学)</text>\r\n</g>\r\n<!-- 7&#45;&gt;End -->\r\n<g id=\"edge13\" class=\"edge\">\r\n<title>7&#45;&gt;End</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M85.76,-196.69C84.07,-182.95 81.89,-163.12 81,-145.7 79.69,-120.1 81.43,-91.32 83.5,-68.91\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"87,-69.08 84.5,-58.78 80.04,-68.39 87,-69.08\"/>\r\n<text text-anchor=\"middle\" x=\"142\" y=\"-124\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(芬兰(Finland)|在)</text>\r\n</g>\r\n<!-- 8 -->\r\n<g id=\"node10\" class=\"node\">\r\n<title>8</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"230\" cy=\"-127.7\" rx=\"18\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"230\" y=\"-124\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8</text>\r\n</g>\r\n<!-- 7&#45;&gt;8 -->\r\n<g id=\"edge11\" class=\"edge\">\r\n<title>7&#45;&gt;8</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M103.2,-204.6C127.86,-189.84 176.79,-160.55 206.13,-142.98\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"208.13,-145.87 214.91,-137.73 204.53,-139.86 208.13,-145.87\"/>\r\n<text text-anchor=\"middle\" x=\"194.5\" y=\"-167.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(芬|在)</text>\r\n</g>\r\n<!-- 8&#45;&gt;End -->\r\n<g id=\"edge12\" class=\"edge\">\r\n<title>8&#45;&gt;End</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M215.34,-116.75C193.09,-101.65 150.23,-72.57 120.42,-52.34\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"122.24,-49.35 112,-46.63 118.31,-55.14 122.24,-49.35\"/>\r\n<text text-anchor=\"middle\" x=\"202.5\" y=\"-80.5\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">P(兰|芬)</text>\r\n</g>\r\n</g>\r\n</svg>\r\n",
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2ab2bb0b3c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "f = graphviz.Digraph()\n",
    "f.attr(size='8,8')\n",
    "f.attr('node', shape='doublecircle')\n",
    "f.node('End')\n",
    "f.node('Start')\n",
    "f.attr('node', shape='circle')\n",
    "f.edge('Start', '1',label='P(赫|begin)')\n",
    "f.edge('1', '2', label='P(尔|赫)')\n",
    "f.edge('2', '3',label='P(辛|尔)')\n",
    "f.edge('3', '4',label='P(基|辛)')\n",
    "f.edge('Start', '4',label='P(赫尔辛基(Helsinki)|begin)')\n",
    "\n",
    "f.edge('4', '5',label='P(大|基)')\n",
    "f.edge('5', '6',label='P(学|大)')\n",
    "f.edge('4', '6',label='P(大学(University)|基 or 赫尔辛基 )')\n",
    "f.edge('Start', '6',label='P(赫尔辛基大学(University of Helsinki)|begin)')\n",
    "f.edge('6', '7',label='P(在|学 or 大学 or 赫尔辛基大学)')\n",
    "f.edge('7', '8',label='P(芬|在)')\n",
    "f.edge('8', 'End',label='P(兰|芬)')\n",
    "f.edge('7', 'End',label='P(芬兰(Finland)|在)')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4bae84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T22:01:15.034310Z",
     "start_time": "2021-12-23T22:01:15.018313Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_sentence(sentence,pre_word_dict,word_dict):\n",
    "    cutpoint={}\n",
    "    l=len(sentence)\n",
    "    #'''\n",
    "    #add regular expression\n",
    "    time_pattern=\"([0-9零一二三四五六七八九十o○.]{2,}[年月日点时分秒%]*)\"\n",
    "    time_list=re.findall(\"([0-9零一二三四五六七八九十o○.]{2,}[年月日点时分秒%]*)\",sentence)\n",
    "    sentence=re.sub(time_pattern,\"T\",sentence)\n",
    "    #add regular expression\n",
    "    #'''\n",
    "    for i in range(l):#generating directed acyclic graph\n",
    "        cutpoint[i]=[]\n",
    "        for j in range(i,l):\n",
    "            if sentence[i:j+1] in word_dict:\n",
    "                cutpoint[i].append(j)\n",
    "        if cutpoint[i]==[]:\n",
    "            cutpoint[i].append(i)\n",
    "    #print(cutpoint)\n",
    "    prenode=dict.fromkeys(range(l), 0) # set node 0 as default\n",
    "    node_cost=[]\n",
    "    #best_pre=[] \n",
    "    for i in cutpoint:\n",
    "        if i ==0:\n",
    "            for j in cutpoint[i]:\n",
    "                node_cost.append([-1,-1,0,j,interpolated_prob(\"<begin>\",sentence[i:j+1],pre_word_dict,word_dict)])\n",
    "                #best_index,best_cost=(min([(j,interpolated_prob(\"<begin>\",sentence[i:j+1],pre_word_dict,word_dict)) for j in cutpoint[i]]))\n",
    "                prenode[(i,j)]=(-1,-1)\n",
    "                \n",
    "        else:\n",
    "            if i-1 in [n[3] for n in node_cost]:# only if previous index is an ending index of a word\n",
    "                for j in cutpoint[i]:\n",
    "                    node_cost.append(min([(n[2],n[3],i,j,\n",
    "                                          n[4]+interpolated_prob(sentence[n[2]:n[3]+1],sentence[i:j+1],pre_word_dict,word_dict))\n",
    "                                          for n in node_cost if n[3] == i-1]\n",
    "                                         ,key=lambda x:x[4]))\n",
    "                    # node_cost will append a tuple like (i,j,m,n,5.13) where i to j is slice of previous word, m & n are staring and ending index of current word. \n",
    "                    #The last is current weight, and min([],key = the current weight) \n",
    "                #best_index,best_cost=(min([(j,interpolated_prob(sentence[prenode[i-1]:i],sentence[i:j+1],pre_word_dict,word_dict)) for j in cutpoint[i]]))\n",
    "                    prenode[(i,j)]=(node_cost[-1][0],node_cost[-1][1])\n",
    "    #print(node_cost)\n",
    "    back_index=l-1\n",
    "    split=[];result=[]\n",
    "    start,end,low_cost=min([(n[2],n[3],n[4]) for n in node_cost if n[3] == back_index],key=lambda x:x[2])\n",
    "    split.append((start,end))\n",
    "    while back_index>0:\n",
    "        back_index=prenode[split[-1]][0]\n",
    "        split.append(prenode[split[-1]])\n",
    "    for nodes in split[::-1]:\n",
    "        result.append(sentence[nodes[0]:nodes[1]+1])\n",
    "    #'''\n",
    "    #add regular expression    \n",
    "    result='  '.join(result)\n",
    "    for i in range(len(time_list)):\n",
    "        result=result.replace(\"T\",time_list[0],1)\n",
    "        time_list.pop(0)\n",
    "    #add regular expression\n",
    "    #'''\n",
    "    result=''.join(result)# if regular expression function is turned off, reuslt should be '  '.join(result)\n",
    "    return result\n",
    "#split_sentence(\"办案人员还是，\",pre_word_dict,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5068dac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T22:01:47.602831Z",
     "start_time": "2021-12-23T22:01:47.583048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'赫尔辛基  大学  在  芬兰'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_sentence(\"赫尔辛基大学在芬兰\",pre_word_dict,word_dict)# The university of Helsinki is in Finland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c76c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:03:56.106259Z",
     "start_time": "2021-12-23T17:03:49.590093Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'./training_and_testing_data/pku_test.txt',encoding='gbk') as f:# the path may need change\n",
    "    test=f.readlines()\n",
    "for i,s in enumerate(test):\n",
    "    test[i]=split_sentence(s,pre_word_dict,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e82f64e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:04:26.049241Z",
     "start_time": "2021-12-23T17:04:26.027987Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('pku_test_segmentation_bi_re.txt',\"a\") as f:\n",
    "    f.writelines(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef1e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5a51d72b3eb6379af9486925d5d27778613c8fb4a36d2c6459bdf8c05d28839"
  },
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
