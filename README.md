# Chinese-Word-Segmentation  
This repository is my output of Computational morphology final project  
I tackled Chinese Word Segmentation problem with four different approaches which are dictionary-based, N-gram language model(unigram & bigram) and Hidden Markov Model.   
The code directory stores four files with many details of how different algorithms work.  
The result_and_evaluation directory includes results of different models.  
The training_and_testing_data comes from SIGHAN(Special Interest Group on Chinese Language Processing) bakeoff2005.  

